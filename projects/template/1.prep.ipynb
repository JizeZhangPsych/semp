{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# SEMP Preprocessing Tutorial\n",
    "\n",
    "This notebook walks you through adapting the `template` project folder into a working preprocessing pipeline for your own EEG-fMRI dataset.  \n",
    "It mirrors the `projects/sr/` implementation and explains every design decision.\n",
    "\n",
    "---\n",
    "\n",
    "## Overview of steps\n",
    "\n",
    "1. **Standardise the dataset** — ensure every raw EEG file follows a consistent naming pattern\n",
    "2. **Write `pathfinder.py`** — teach semp how to find files on disk\n",
    "3. **Write `initialize()` in `helpers.py`** — fill `dataset` with the metadata your pipeline needs\n",
    "4. **Write the config dict in `1.prep.py`** — run the full preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1 — Standardise the dataset\n",
    "\n",
    "semp's pathfinder works by matching filenames against a **pattern with named placeholders**, e.g.:\n",
    "\n",
    "```\n",
    "/data/eeg-fmri/sub-{subject}_ses-{session}_run-{run}_eeg.edf\n",
    "```\n",
    "\n",
    "This requires that **all** your raw EEG files follow the same naming convention.  \n",
    "If your dataset is inconsistent (mixed separators, varying padding, missing fields), fix it before proceeding.\n",
    "\n",
    "### 1a. Audit your raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Point this at the folder that contains all your raw EEG files (search recursively)\n",
    "RAW_ROOT = Path(\"/path/to/your/raw/eeg/\")\n",
    "\n",
    "# List every .edf (or .fif / .set / .cdt) found under RAW_ROOT\n",
    "raw_files = sorted(RAW_ROOT.rglob(\"*.edf\"))\n",
    "for f in raw_files[:20]:   # show first 20\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "### 1b. Rename files if needed\n",
    "\n",
    "If file names are inconsistent, use `Path.rename()` to enforce a uniform pattern.  \n",
    "The example below parses a legacy naming scheme and renames to BIDS-like names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, shutil\n",
    "\n",
    "DRY_RUN = True   # set to False to actually rename\n",
    "\n",
    "LEGACY_PATTERN = re.compile(r\"(\\d+)_(\\d+)_(\\d+)\\.edf\")   # e.g. 01_02_1.edf → sub-01_ses-02_run-1\n",
    "\n",
    "for f in raw_files:\n",
    "    m = LEGACY_PATTERN.match(f.name)\n",
    "    if m:\n",
    "        subj, ses, run = m.groups()\n",
    "        new_name = f\"sub-{subj.zfill(2)}_ses-{ses.zfill(2)}_run-{run}_eeg.edf\"\n",
    "        new_path = f.parent / new_name\n",
    "        print(f\"{f.name}  →  {new_name}\")\n",
    "        if not DRY_RUN:\n",
    "            f.rename(new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2 — Write `pathfinder.py`\n",
    "\n",
    "The pathfinder is a **frozen dataclass** that:\n",
    "- Stores a `file_patterns` dict mapping *kind* → *glob pattern with `{placeholders}`*\n",
    "- Scans the disk on construction and builds a lookup table: `file_id → kind → Path`\n",
    "- Requires you to implement two methods: `dict2id` and `id2dict`\n",
    "\n",
    "### Design decisions you must make\n",
    "\n",
    "| Question | Example answer |\n",
    "|---|---|\n",
    "| What are the fields that uniquely identify a recording? | `subject`, `session`, `run` |\n",
    "| What is a compact string identifier (`file_id`) for a recording? | `\"0121\"` for sub=01, ses=02, run=01 |\n",
    "| What is the **anchor** kind — the file that *must* exist for a recording to be included? | `\"raw\"` |\n",
    "| Which kinds are **required** (remove the file_id if missing)? | `{\"raw\", \"polhemus\"}` |\n",
    "\n",
    "### Template `pathfinder.py`\n",
    "\n",
    "Copy this into `projects/<your_project>/pathfinder.py` and customise it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── pathfinder.py (copy to your project folder) ─────────────────────────────\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "from semp.utils import BasePathfinder\n",
    "\n",
    "\n",
    "class MyDatasetPathfinder(BasePathfinder):\n",
    "    \"\"\"\n",
    "    Pathfinder for <your dataset name>.\n",
    "\n",
    "    File ID convention: zero-padded subject (2 digits) + session (1 digit) + run (1 digit).\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    sub-01, ses-02, run-1  →  file_id \"0121\"\n",
    "    sub-11, ses-01, run-2  →  file_id \"1112\"\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_FILE_PATTERNS = {\n",
    "        # ── anchor: the raw EEG file ────────────────────────────────────────\n",
    "        # Use {subject}, {session}, {run} as placeholders.\n",
    "        # You can use {foo1}, {foo2}, … for parts of the name you don't care about.\n",
    "        'raw': \"/path/to/raw/sub-{subject}_ses-{session}_run-{run}_{foo1}_eeg.edf\",\n",
    "\n",
    "        # ── optional: polhemus digitisation file ────────────────────────────\n",
    "        'polhemus': \"/path/to/raw/sub-{subject}/ses-{session}/polhemus/{foo1}.pom\",\n",
    "\n",
    "        # ── output: filled in after preprocessing ───────────────────────────\n",
    "        'preproc': \"/path/to/output/{subject}{session}{run}/{subject}{session}{run}_preproc-raw.fif\",\n",
    "        ### Note: any string including }{ is an \"ambiguous pattern\" that cannot be used as an anchor. You need at least one unambiguous pattern (without }{) to serve as the anchor for scanning the disk.\n",
    "    }\n",
    "    DEFAULT_ANCHOR = \"raw\"      # scan disk using this kind's pattern\n",
    "    REQUIRED_KEYS  = {\"raw\"}    # remove file_id from pathfinder if this kind is missing\n",
    "\n",
    "    def __init__(self, file_patterns=None, anchor=None):\n",
    "        patterns = file_patterns or self.DEFAULT_FILE_PATTERNS\n",
    "        chosen_anchor = anchor or self.DEFAULT_ANCHOR\n",
    "        super().__init__(file_patterns=patterns, anchor=chosen_anchor, required=self.REQUIRED_KEYS)\n",
    "\n",
    "    # ── required: compact string identifier ─────────────────────────────────\n",
    "    def dict2id(self, fields: Dict[str, Optional[str]]) -> str:\n",
    "        \"\"\"Fields dict  →  canonical file_id string.\"\"\"\n",
    "        subj = (fields.get('subject') or '1').lstrip('0') or '1'\n",
    "        ses  = fields.get('session', '1')\n",
    "        run  = fields.get('run',     '1')\n",
    "        return f\"{subj}{ses}{run}\"\n",
    "\n",
    "    # ── required: reverse mapping ────────────────────────────────────────────\n",
    "    def id2dict(self, file_id: str) -> Dict[str, str]:\n",
    "        \"\"\"Canonical file_id string  →  fields dict.\"\"\"\n",
    "        if len(file_id) < 3:\n",
    "            raise ValueError(f\"Invalid file_id: '{file_id}'\")\n",
    "        return {\n",
    "            'subject': file_id[:-2].zfill(2),   # zero-pad subject to 2 digits\n",
    "            'session': file_id[-2],\n",
    "            'run':     file_id[-1],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "### Verify the pathfinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = MyDatasetPathfinder()\n",
    "\n",
    "print(f\"Found {len(pf)} recordings:\\n\")\n",
    "for fid in list(pf.keys())[:5]:   # show first 5\n",
    "    print(f\"  {fid}:\")\n",
    "    for kind, path in pf[fid].items():\n",
    "        status = \"✓\" if path is not None else \"✗ (missing)\"\n",
    "        print(f\"    {kind:<12} {status}  {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2a3",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3 — Write `initialize()` in `helpers.py`\n",
    "\n",
    "`initialize()` is the **first step** in every `run_proc_chain` call.  \n",
    "It populates `dataset` with the metadata that all later steps depend on.\n",
    "\n",
    "The five keys you **must** set are described below.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1  `tr_interval` — the fMRI TR (repetition time)\n",
    "\n",
    "This is stated in the MRI protocol (e.g. TR = 1.14 s for the Staresina dataset).  \n",
    "It is used by `crop_TR` to align the EEG timeline with the fMRI volumes.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2  `slice_interval` — the fMRI slice timing\n",
    "\n",
    "This is the time between consecutive slice acquisitions (TR / number-of-slices).  \n",
    "It determines the dominant gradient artifact frequency: `1/slice_interval` Hz.\n",
    "\n",
    "**If your MRI protocol sheet does not list it**, inspect the raw EEG PSD:  \n",
    "gradient artifact peaks appear at harmonics of `1/slice_interval` Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from semp.eeg import psd_plot\n",
    "\n",
    "# Load one raw file (before any cleaning)\n",
    "raw = mne.io.read_raw_edf(\"/path/to/one/raw_eeg.edf\", preload=True)\n",
    "\n",
    "# Plot PSD up to 30 Hz — the tallest regularly spaced peaks are GA harmonics.\n",
    "# E.g. peaks at 14.3, 28.6 Hz  →  slice_interval = 1/14.3 ≈ 0.07 s\n",
    "psd_plot(raw, picks='eeg', fmin=0, fmax=50, dB=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.3  `tr_event_key` — the annotation label for TR triggers\n",
    "\n",
    "The EEG amplifier records a trigger at every fMRI volume onset.  \n",
    "Find the annotation label whose inter-event interval is consistently equal to `tr_interval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get all events and their labels\n",
    "events, event_id = mne.events_from_annotations(raw)\n",
    "print(\"All annotation labels and their event codes:\")\n",
    "for label, code in event_id.items():\n",
    "    print(f\"  code={code:>8}  label='{label}'\")\n",
    "\n",
    "print()\n",
    "TR = 1.14     # ← replace with your tr_interval\n",
    "sfreq = raw.info['sfreq']\n",
    "TR_samples = TR * sfreq\n",
    "\n",
    "print(f\"Looking for events with inter-event spacing ≈ {TR_samples:.1f} samples ({TR} s):\\n\")\n",
    "for label, code in event_id.items():\n",
    "    mask = events[:, 2] == code\n",
    "    times = events[mask, 0]\n",
    "    if len(times) < 2:\n",
    "        continue\n",
    "    diffs = np.diff(times)\n",
    "    mean_diff = diffs.mean()\n",
    "    std_diff  = diffs.std()\n",
    "    print(f\"  '{label}': n={len(times)}, mean_interval={mean_diff/sfreq:.4f}s, std={std_diff/sfreq:.4f}s\")\n",
    "    # A good TR key has mean ≈ TR and very low std (< 1 sample jitter)\n",
    "    if abs(mean_diff - TR_samples) < 2 and std_diff < 5:\n",
    "        print(f\"    ^^^ CANDIDATE TR event key: '{label}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.4  `he_event_key` — helium pump trigger (optional)\n",
    "\n",
    "Some sites record the helium pump cycle as a trigger.  \n",
    "This is only needed if you plan to remove the helium pump artifact via OBS (mainly contaminating 30Hz+ data).  \n",
    "**You can safely set this to `[]` or skip it entirely if you are not interested in >30 Hz information.**\n",
    "\n",
    "---\n",
    "\n",
    "### Full `initialize()` template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── helpers.py (copy to your project folder and fill in the constants) ────────\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from semp.utils import psd_band_ratio\n",
    "from pathfinder import MyDatasetPathfinder\n",
    "\n",
    "\n",
    "def initialize(dataset, userargs):\n",
    "    \"\"\"Populate dataset with all metadata needed by the preprocessing pipeline.\"\"\"\n",
    "\n",
    "    # ── 3.1  fMRI repetition time (seconds) ───────────────────────────────────\n",
    "    # Read from your MRI protocol sheet.\n",
    "    dataset['tr_interval']    = userargs.get('tr_interval',    1.14)\n",
    "\n",
    "    # ── 3.2  fMRI slice interval (seconds) ────────────────────────────────────\n",
    "    # = TR / n_slices, or inspected from PSD peaks (see cell above).\n",
    "    dataset['slice_interval'] = userargs.get('slice_interval', 0.07)\n",
    "\n",
    "    # ── 3.3  Annotation label(s) for TR trigger ────────────────────────────────\n",
    "    # Found by running the cell above. Pass as a list of strings.\n",
    "    dataset['tr_event_key']   = userargs.get('tr_event_key',   ['TR_LABEL'])\n",
    "\n",
    "    # ── 3.4  Annotation label(s) for helium pump (optional) ───────────────────\n",
    "    # Set to [] if you do not need OBS helium pump removal.\n",
    "    dataset['he_event_key']   = userargs.get('he_event_key',   [])\n",
    "\n",
    "    # ── 3.5  Output directory ─────────────────────────────────────────────────\n",
    "    dataset['target_pth']     = userargs.get('target_pth',\n",
    "                                             Path(\"/path/to/output/after_prep\"))\n",
    "\n",
    "    # ── Pathfinder & subject ID ───────────────────────────────────────────────\n",
    "    dataset['pf']      = userargs['pf'] if 'pf' in userargs else MyDatasetPathfinder()\n",
    "    dataset['subject'] = dataset['pf'].filename2id(dataset['raw'].filenames[0], kind='raw')\n",
    "\n",
    "    # ── Sampling frequency (for reference) ────────────────────────────────────\n",
    "    dataset['orig_sfreq'] = dataset['raw'].info['sfreq']\n",
    "\n",
    "    # ── Slice-frequency tracers ────────────────────────────────────────────────\n",
    "    ### some extra tracers you want to computer for init_tracer() and summary(). you can safely set it to {} and just use the default tracers provided by semp.\n",
    "    si = dataset['slice_interval']\n",
    "    dataset['tracer'] = {\n",
    "        'psd_slice':  partial(psd_band_ratio,\n",
    "                              band1=[1/si - 1, 1/si + 1], band2='beta', fn1=np.mean),\n",
    "        'psd_2slice': partial(psd_band_ratio,\n",
    "                              band1=[2/si - 1, 2/si + 1], band2=[20, 35], fn1=np.mean),\n",
    "    }\n",
    "\n",
    "    # ── Any dataset-specific fixes go here ────────────────────────────────────\n",
    "    # Example: drop channels with no gel\n",
    "    # dataset['raw'].drop_channels(['F11', 'F12'], on_missing='warn')\n",
    "    \n",
    "    # Example2: do some special custom fix for subject 05 session 2 run 1\n",
    "    # if dataset['subject'] == '05' and dataset['session'] == '2' and dataset['run'] == '1':\n",
    "    #     do_something_special(dataset['raw'])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4 — Write the preprocessing config in `1.prep.py`\n",
    "\n",
    "The config is a list of steps passed to `osl_ephys.preprocessing.run_proc_batch`.  \n",
    "Each step is a `{function_name: kwargs}` dict. Custom functions are passed via `extra_funcs`.\n",
    "\n",
    "The pipeline below is the **standard semp EEG-fMRI preprocessing sequence**.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.1  Initialisation, montage, notch, TR crop\n",
    "\n",
    "- `initialize` — fills `dataset` (Step 3 above)\n",
    "- `set_channel_types` — mark EOG/ECG/EMG channels by name (check your channel list)\n",
    "- `set_channel_montage` — apply digitised electrode positions\n",
    "- `notch_filter` — remove line noise (50 Hz + harmonics in Europe)\n",
    "- `crop_TR` — trim the recording to whole TR intervals using the TR trigger\n",
    "\n",
    "### 4.2  Gradient artifact removal (AAS)\n",
    "\n",
    "- `create_epoch` — epoch the raw data into TR-length windows\n",
    "- `epoch_aas` — average artifact subtraction (AAS): subtracts the mean TR template\n",
    "- `voltage_correction` — rescale EOG/ECG/EMG channels that are mislabelled as V instead of µV, this is a thing in Staresina dataset\n",
    "\n",
    "### 4.3  Bandpass filter + mid-crop\n",
    "\n",
    "- `filter` — 5th-order Butterworth IIR (0.5–125 Hz). **Use IIR, not FIR**: FIR does not fully attenuate out-of-band frequencies here.\n",
    "- `mid_crop` — removes 5 s from each edge to prevent filter edge artefacts before resampling\n",
    "- `resample` — downsample to 250 Hz\n",
    "\n",
    "### 4.4  Bad segment and channel detection\n",
    "\n",
    "- Three `bad_segments` passes: amplitude + diff mode for EEG, amplitude for EOG\n",
    "- `bad_channels` — detect and mark globally bad EEG channels\n",
    "\n",
    "### 4.5  Slice ICA (residual GA removal)\n",
    "\n",
    "- `slice_ica` — ICA targeting `1/slice_interval` Hz and its harmonics.  \n",
    "  AAS leaves a residual because it assumes a stationary template; slice_ica cleans the remainder.\n",
    "\n",
    "### 4.6  General ICA (pulse & ocular artefacts)\n",
    "\n",
    "- `ica_raw` — fit ICA on the cleaned broadband signal\n",
    "- `ica_autoreject` — automatically label components as EOG (correlation), ECG (CTPS, threshold 0.1), and apply rejection\n",
    "  - If automatic rejection misses artifacts or removes brain components, set `apply=False` here and inspect IC topos/time-series manually before applying.\n",
    "\n",
    "### 4.7  Final bad channels, interpolation, re-reference\n",
    "\n",
    "- `bad_channels` — second pass after ICA (ICA sometimes reveals previously hidden bad channels)\n",
    "- `interpolate_bads` — spherical spline interpolation of marked bad channels\n",
    "- `set_eeg_reference` — average reference (projection-based)\n",
    "\n",
    "---\n",
    "\n",
    "### Full `1.prep.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 1.prep.py (copy to your project folder and adjust the constants) ─────────\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from osl_ephys.preprocessing import run_proc_batch\n",
    "\n",
    "from pathfinder import MyDatasetPathfinder\n",
    "from helpers import initialize\n",
    "\n",
    "from semp.eeg import (\n",
    "    crop_TR, epoch_aas, epoch_obs, create_epoch,\n",
    "    ckpt_report, slice_ica, init_tracer, summary,\n",
    "    mid_crop, set_channel_type_raw, voltage_correction,\n",
    ")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Global settings — change these for your dataset\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "TR             = 1.14          # fMRI repetition time (seconds)\n",
    "SLICE_INTERVAL = 0.07          # fMRI slice interval (seconds) — TR / n_slices\n",
    "TR_EVENT_KEY   = ['TR_LABEL']  # annotation label(s) for TR trigger\n",
    "HE_EVENT_KEY   = []            # helium pump label(s); set [] to skip\n",
    "TARGET_PTH     = Path(\"/path/to/output/after_prep\")\n",
    "\n",
    "continue_interrupt = True      # skip subjects already finished or errored\n",
    "\n",
    "pf = MyDatasetPathfinder()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Preprocessing config\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "config = {\n",
    "    'preproc': [\n",
    "\n",
    "        # ── 4.1  Init, montage, notch, TR crop ────────────────────────────────\n",
    "        {'initialize': {\n",
    "            'target_pth':     TARGET_PTH,\n",
    "            'pf':             pf,\n",
    "            'tr_interval':    TR,\n",
    "            'slice_interval': SLICE_INTERVAL,\n",
    "            'tr_event_key':   TR_EVENT_KEY,\n",
    "            'he_event_key':   HE_EVENT_KEY,\n",
    "        }},\n",
    "        {'init_tracer': {}},\n",
    "        # Rename EOG/ECG/EMG channels to their correct types:\n",
    "        {'set_channel_types': {'VEOG': 'eog', 'HEOG': 'eog', 'EKG': 'ecg', 'EMG': 'emg'}},\n",
    "        {'notch_filter': {'freqs': '50 100'}},\n",
    "        {'crop_TR': {'tmin': 0, 'TR': TR}},\n",
    "        {'ckpt_report': {'ckpt_name': 'raw', 'focus_range': [0, 10], 'dB': False}},\n",
    "\n",
    "        # ── 4.2  Gradient artifact removal (AAS) ──────────────────────────────\n",
    "        {'create_epoch': {'event': 'TR', 'tmin': 0, 'tmax': TR, 'correct_trig': True}},\n",
    "        {'epoch_aas': {'epoch_key': 'tr_ep', 'overwrite': 'new',\n",
    "                       'picks': 'all', 'window_length': 30, 'fit': False}},\n",
    "        {'voltage_correction': {}},\n",
    "        {'ckpt_report': {'ckpt_name': 'after_aas_removal',\n",
    "                         'key_to_print': 'tr_ep', 'dB': False}},\n",
    "\n",
    "        # ── 4.3  Bandpass + mid-crop + resample ───────────────────────────────\n",
    "        # IIR Butterworth preferred over FIR: better out-of-band attenuation here.\n",
    "        {'filter': {'l_freq': 0.5, 'h_freq': 125,\n",
    "                    'method': 'iir', 'iir_params': {'order': 5, 'ftype': 'butter'}}},\n",
    "        # Remove 5 s edges to prevent filter ringing before downsampling.\n",
    "        {'mid_crop': {'edge': 5}},\n",
    "        {'resample': {'sfreq': 250}},\n",
    "        {'ckpt_report': {'ckpt_name': 'after_filt', 'dB': False}},\n",
    "\n",
    "        # ── 4.4  Bad segment & channel detection ──────────────────────────────\n",
    "        {'bad_segments': {'segment_len': 500, 'picks': 'eeg',\n",
    "                          'significance_level': 0.1, 'detect_zeros': False}},\n",
    "        {'bad_segments': {'segment_len': 500, 'picks': 'eeg', 'mode': 'diff',\n",
    "                          'significance_level': 0.1, 'detect_zeros': False}},\n",
    "        {'bad_channels': {'picks': 'eeg', 'significance_level': 0.1}},\n",
    "        {'bad_segments': {'segment_len': 2500, 'picks': 'eog', 'detect_zeros': False}},\n",
    "\n",
    "        # ── 4.5  Slice ICA — residual gradient artifact ────────────────────────\n",
    "        # Targets 1/slice_interval Hz and its harmonics.\n",
    "        # Required because AAS assumes a stationary artifact template.\n",
    "        {'slice_ica': {}},\n",
    "        {'ckpt_report': {'ckpt_name': 'after_bads_trica', 'dB': False}},\n",
    "\n",
    "        # ── 4.6  General ICA — pulse artifact, EOG, ECG ───────────────────────\n",
    "        # n_components=0.999 retains 99.9 % of EEG variance.\n",
    "        # ica_autoreject: EOG by correlation (0.35), ECG by CTPS (0.1).\n",
    "        # For a harder dataset or finer control, set apply=False and inspect\n",
    "        # component topographies and time-series before deciding what to reject.\n",
    "        {'ica_raw': {'n_components': 0.999, 'picks': 'eeg', 'l_freq': 1}},\n",
    "        {'ica_autoreject': {'eogmeasure': 'correlation', 'eogthreshold': 0.35,\n",
    "                            'ecgmethod': 'ctps', 'ecgthreshold': 0.1, 'apply': True}},\n",
    "\n",
    "        # ── 4.7  Final bad channels, interpolation, re-reference ──────────────\n",
    "        {'bad_channels': {'picks': 'eeg', 'significance_level': 0.1}},\n",
    "        {'interpolate_bads': {}},\n",
    "        {'ckpt_report': {'ckpt_name': 'after_ica', 'dB': False}},\n",
    "        {'set_eeg_reference': {'projection': True}},\n",
    "        {'summary': {}},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Build subject/file lists (skip already-finished or errored subjects)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "subject_list = list(pf.keys())\n",
    "file_list    = [pf[s]['raw'] for s in subject_list]\n",
    "\n",
    "if continue_interrupt:\n",
    "    finished = {p.parts[-2] for p in TARGET_PTH.glob('*/*_preproc-raw.fif')}\n",
    "    errored  = {p.parts[-1].split('_')[0] for p in TARGET_PTH.glob('logs/*.error.log')}\n",
    "\n",
    "    pairs = [(s, f) for s, f in zip(subject_list, file_list)\n",
    "             if s not in finished and s not in errored]\n",
    "    if pairs:\n",
    "        subject_list, file_list = zip(*pairs)\n",
    "    else:\n",
    "        subject_list, file_list = [], []\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Run\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "run_proc_batch(\n",
    "    config, list(file_list),\n",
    "    subjects=list(subject_list),\n",
    "    outdir=str(TARGET_PTH),\n",
    "    gen_report=False,\n",
    "    overwrite=True,\n",
    "    extra_funcs=[\n",
    "        initialize, init_tracer, crop_TR, set_channel_type_raw,\n",
    "        create_epoch, epoch_aas, epoch_obs, voltage_correction,\n",
    "        ckpt_report, mid_crop, slice_ica, summary,\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
